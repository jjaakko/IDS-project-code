{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkJ2Y8BeEihg"
   },
   "source": [
    "# Fake news classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0grTghFBZGzs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "a5aFFjGrkB_s",
    "outputId": "6fb8007a-034b-4156-fc76-3aeaf34aaf82"
   },
   "outputs": [],
   "source": [
    "# Download and unzip data unless the file already exists.\n",
    "if not os.path.exists(\"./fake.json.zip\"):\n",
    "  !wget -O fake.json.zip https://www.dropbox.com/s/fs613hv1u24cjb9/fake_news_reddit_cikm20.json.zip?dl=0\n",
    "  !unzip fake.json.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjOVuO-npjvy"
   },
   "outputs": [],
   "source": [
    "df = pd.read_json(\"fake_news_reddit_cikm20.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kc638jrDZpB5",
    "outputId": "1a54000d-8ad1-467c-d667-8e0b06f4ae5e"
   },
   "outputs": [],
   "source": [
    "r = np.random.RandomState(42)\n",
    "# Note: use small sample to for testing out different ideas or looking at parts of the data\n",
    "# by uncommenting the following.\n",
    "#df.sample(n=5000, replace=False, random_state=r)\n",
    "\n",
    "# Comment this out if using a smaller sample.\n",
    "sample = df.copy()\n",
    "\n",
    "# Calculate tfidf vectors\n",
    "corpus = sample[\"text\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2,ngram_range=(1,1))\n",
    "# Note tested with ngram sizes (1,2) and (2,2)\n",
    "# ngram size (1,2) did not improve the results notably.\n",
    "\n",
    "tfidf_vectorizer.fit(corpus)\n",
    "tfidf_vectors = tfidf_vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Olenainen koodi lataamiseen\n",
    "import joblib\n",
    "vectorizer2 = joblib.load(\"tfidf_vectorizer.joblib\")\n",
    "tfidf_vectors2 = joblib.load(\"tfidf_vectors.joblib\")\n",
    "model2 = joblib.load(\"logreg-model-with-all-data-balanced-2.joblib\")\n",
    "X = tfidf_vectors2\n",
    "y = df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for saving the feature vectors.\n",
    "import joblib\n",
    "joblib.dump(tfidf_vectorizer, \"tfidf_vectorizer.joblib\")\n",
    "joblib.dump(tfidf_vectors, \"tfidf_vectors.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for generating wordcloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf_idf_row_as_list = np.squeeze(tfidf_vectors2[19912].toarray())\n",
    "indices = np.argsort(tf_idf_row_as_list)[::-1]\n",
    "\n",
    "word_cloud_dict = {}\n",
    "for i in indices[0:50]:\n",
    "    #print(f\"{features[i]}: {row_pos[i]}\")\n",
    "    print(features_df[0][i])\n",
    "    word_cloud_dict[features_df[0][i]] = tf_idf_row_as_list[i]\n",
    "\n",
    "wordcloud = WordCloud().generate_from_frequencies(word_cloud_dict)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"wordcloud.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning arbitraty text into a featuire vector\n",
    "example_document = vectorizer2.transform(['text goes here'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5IeZMKtZ66N"
   },
   "outputs": [],
   "source": [
    "# Split for test and training data.\n",
    "X = tfidf_vectors\n",
    "y = sample[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zladcHZch0T_",
    "outputId": "0dab5455-fbf7-4f6a-8c66-5db0d5a9209f"
   },
   "outputs": [],
   "source": [
    "# In case we want to have a look at the words.\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "features_df = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to track down docs in which documents specific feature is present.\n",
    "def doc_indexes_where_feature_present(tfidf_vectors, features, feature_name):\n",
    "\n",
    "    col = features.index(feature_name)\n",
    "    rows, cols = tfidf_vectors[:,col].nonzero()\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def get_non_zero_tf_idf_scores_by_feature_name(tfidf_vectors, features, feature_name):\n",
    "\n",
    "    col = features.index(feature_name)\n",
    "    rows, cols = tfidf_vectors[:,col].nonzero()\n",
    "    \n",
    "    # Get all tfidf scores for given feature name\n",
    "    tf_idf_scores = tfidf_vectors[rows, col].todense()\n",
    "    return tf_idf_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9DWo8jPkSPn"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = LogisticRegression(max_iter=4000, class_weight=\"balanced\")\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkyX9Gw55WT8"
   },
   "outputs": [],
   "source": [
    "# Check the scores\n",
    "print(\n",
    "\"Accuracy:\", accuracy_score(y_test,predictions),\n",
    "\"\\nPrecision:\", precision_score(y_test,predictions),\n",
    "\"\\nRecall:\", recall_score(y_test,predictions),\n",
    "\"\\nF1:\", f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix.\n",
    "mat = confusion_matrix(y_test, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(mat.T, ax=ax, fmt=\"d\", square=True, annot=True, cbar=False, cmap=\"YlGnBu\")\n",
    "ax.set_xlabel(\"True label\")\n",
    "ax.set_ylabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for saving the model.\n",
    "from joblib import dump, load\n",
    "dump(model, \"logreg-model-with-all-data-balanced.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for loading the model\n",
    "from joblib import dump, load\n",
    "mod = load(\"tfidf-model-with-all-data-balanced.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give it a go with random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    max_depth=None,\n",
    "    n_estimators=200,\n",
    "    random_state=0\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_predtrain_rf = rf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fake_news_classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
